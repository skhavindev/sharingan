# ğŸ‘ï¸ Sharingan - Semantic Video Understanding

<p align="center">
  <img src="https://media1.tenor.com/m/YeM3fMlamBoAAAAd/naruto.gif" alt="Sharingan GIF" style="width:100%; height:auto;"/>
</p>


**Sharingan** is a lightweight Python library for semantic video understanding with temporal reasoning. It combines vision-language models (CLIP, SmolVLM) with temporal analysis to understand video content at a deep semantic level.

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

---

## âœ¨ Features

* ğŸ¬ **Semantic Video Processing** â€“ Understand video content beyond pixels
* ğŸ” **Natural Language Queries** â€“ Search videos using text descriptions
* ğŸ¤– **AI Chat** â€“ Conversational interface with Qwen2.5-0.5B
* âš¡ **Temporal Reasoning** â€“ Cross-frame attention and memory tokens
* ğŸ¯ **Event Detection** â€“ Automatically identify key moments
* ğŸ’¾ **Efficient Storage** â€“ 130x compression with Int8 quantization
* ğŸŒ **Web UI** â€“ Beautiful Flask-based interface
* ğŸš€ **Fast Processing** â€“ Batch processing and GPU acceleration

---
You can read the [Author Note](https://github.com/skhavindev/sharingan/blob/master/author_note.md), check out the [Architecture](https://github.com/skhavindev/sharingan/blob/master/architecture.md), and see the [Contributing Guidelines](https://github.com/skhavindev/sharingan/blob/master/contributing.md) on GitHub.

---

## ğŸš€ Quick Start

### Installation

```bash
pip install sharingan-core

# Optional: GPU acceleration
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118

# Optional: AI chat
pip install transformers bitsandbytes accelerate
```

### Basic Usage

```python
from sharingan import VideoProcessor

processor = VideoProcessor(
    vlm_model='clip',  # or 'smolvlm'
    device='auto'
)

results = processor.process('video.mp4')

matches = processor.query('person speaking')
for match in matches:
    print(f"Found at {match.timestamp}s - {match.confidence:.2%}")

response = processor.chat('What happens in this video?')
print(response)
```

### Web UI

```bash
python -m sharingan.cli ui
```

Or programmatically:

```python
from sharingan.ui import run_ui
run_ui(port=5000, open_browser=True)
```

---

## ğŸ“– Documentation

**Vision Models**

* **CLIP** â€“ Fast semantic embeddings; memory ~400MB
* **SmolVLM-500M** â€“ Detailed frame descriptions; memory ~538MB (8-bit quantized)

**Processing Options**

```python
processor = VideoProcessor(
    vlm_model='clip',
    device='auto',
    target_fps=5.0,
    enable_temporal=True,
    enable_tracking=False
)
```

**Query Options**

```python
results = processor.query('person speaking', top_k=5)
response = processor.chat('Describe main events', use_llm=True)
```

---

## ğŸ¯ Use Cases

* Video Search â€“ Find moments using natural language
* Content Moderation â€“ Detect inappropriate content
* Video Summarization â€“ Auto summaries
* Accessibility â€“ Descriptions for visually impaired
* Research â€“ Analyze video datasets at scale

---

## ğŸ”§ Advanced Features

**Temporal Reasoning**

* Cross-Frame Gating â€“ Learns important frames
* Memory Tokens â€“ Maintains context across video
* Temporal Attention â€“ Understand relationships between frames

**Efficient Storage**

* 5-min video: ~2.3MB (vs 300MB raw)
* Fast cache loading
* Minimal quality loss for search

**Event Detection**

* Scene changes
* Motion patterns
* Content transitions

---

## ğŸ“Š Performance

| Model   | Speed | Memory | Quality   |
| ------- | ----- | ------ | --------- |
| CLIP    | âš¡âš¡âš¡   | 400MB  | Good      |
| SmolVLM | âš¡âš¡    | 538MB  | Excellent |

*Tested on NVIDIA RTX 3060 (4GB VRAM)*

---

## ğŸ¤ Contributing

Contributions welcome! Please submit a PR.

## ğŸ“„ License

MIT License â€“ see LICENSE file.

## ğŸ™ Acknowledgments

* [OpenAI CLIP](https://github.com/openai/CLIP)
* [SmolVLM](https://huggingface.co/HuggingFaceTB/SmolVLM-500M-Instruct)
* [Qwen2.5](https://huggingface.co/Qwen/Qwen2.5-0.5B-Instruct)

## ğŸ“§ Contact

Open an issue on GitHub for support.

---

Made with â˜• & â¤ï¸

